{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6MJUuuXc-OA",
        "outputId": "8b1fb29f-42ee-44c0-ad35-eb6133571353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "def audio_to_spectrogram(file_path):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_path, sr=None)\n",
        "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "        return mel_spec_db\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def augment_audio(file_path):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_path, sr=None)\n",
        "        stretched_audio = librosa.effects.time_stretch(audio, rate=0.8)\n",
        "        pitch_shifted_audio = librosa.effects.pitch_shift(audio, sr=sample_rate, n_steps=3)\n",
        "        noise = np.random.randn(len(audio))\n",
        "        noise_audio = audio + 0.005 * noise\n",
        "        return [\n",
        "            librosa.power_to_db(librosa.feature.melspectrogram(y=stretched_audio, sr=sample_rate), ref=np.max),\n",
        "            librosa.power_to_db(librosa.feature.melspectrogram(y=pitch_shifted_audio, sr=sample_rate), ref=np.max),\n",
        "            librosa.power_to_db(librosa.feature.melspectrogram(y=noise_audio, sr=sample_rate), ref=np.max)\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error augmenting {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "def resize_spectrogram(spectrogram, target_size=(128, 128)):\n",
        "    resized = cv2.resize(spectrogram, target_size, interpolation=cv2.INTER_AREA)\n",
        "    return resized\n",
        "\n",
        "def load_data(data_paths):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "\n",
        "    for label, data_path in enumerate(data_paths):\n",
        "        audio_files = [f for f in os.listdir(data_path) if f.endswith('.wav')]\n",
        "        for file in audio_files:\n",
        "            file_path = os.path.join(data_path, file)\n",
        "            mel_spectrogram = audio_to_spectrogram(file_path)\n",
        "\n",
        "            if mel_spectrogram is not None:\n",
        "                resized_spectrogram = resize_spectrogram(mel_spectrogram)\n",
        "                spectrograms.append(resized_spectrogram)\n",
        "                labels.append(label)\n",
        "\n",
        "                augmented_spectrograms = augment_audio(file_path)\n",
        "                for aug_spec in augmented_spectrograms:\n",
        "                    resized_aug_spectrogram = resize_spectrogram(aug_spec)\n",
        "                    spectrograms.append(resized_aug_spectrogram)\n",
        "                    labels.append(label)\n",
        "\n",
        "    spectrograms = np.array(spectrograms)\n",
        "    spectrograms = (spectrograms - np.mean(spectrograms)) / np.std(spectrograms)\n",
        "    spectrograms = np.expand_dims(spectrograms, axis=-1)\n",
        "\n",
        "    return spectrograms, np.array(labels)\n",
        "\n",
        "train_data_paths = [\n",
        "    '/content/drive/MyDrive/miniproject/birds/train/amerad',\n",
        "    '/content/drive/MyDrive/miniproject/birds/train/comter',\n",
        "    '/content/drive/MyDrive/miniproject/birds/train/rewbla'\n",
        "]\n",
        "\n",
        "val_data_paths = [\n",
        "    '/content/drive/MyDrive/miniproject/birds/validation/amerad',\n",
        "    '/content/drive/MyDrive/miniproject/birds/validation/comter',\n",
        "    '/content/drive/MyDrive/miniproject/birds/validation/rewbla'\n",
        "]\n",
        "\n",
        "X_train, y_train = load_data(train_data_paths)\n",
        "X_val, y_val = load_data(val_data_paths)\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=X_train[0].shape),\n",
        "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/miniproject/bird_species_classifier_three_birds_v5.keras')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU4LobyBdADb",
        "outputId": "31015dd4-c239-4abd-e22f-7c04643e4647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 823ms/step - accuracy: 0.4477 - loss: 1.3458 - val_accuracy: 0.6133 - val_loss: 1.1175 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 822ms/step - accuracy: 0.7058 - loss: 1.0071 - val_accuracy: 0.6933 - val_loss: 0.9467 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 817ms/step - accuracy: 0.7580 - loss: 0.8560 - val_accuracy: 0.6917 - val_loss: 0.8963 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 808ms/step - accuracy: 0.7909 - loss: 0.7541 - val_accuracy: 0.7000 - val_loss: 0.9099 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 816ms/step - accuracy: 0.8069 - loss: 0.6858 - val_accuracy: 0.6867 - val_loss: 0.9076 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 826ms/step - accuracy: 0.8594 - loss: 0.5980 - val_accuracy: 0.6817 - val_loss: 0.9000 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 822ms/step - accuracy: 0.8622 - loss: 0.5780 - val_accuracy: 0.7300 - val_loss: 0.8497 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 806ms/step - accuracy: 0.8905 - loss: 0.5037 - val_accuracy: 0.7183 - val_loss: 0.8486 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 821ms/step - accuracy: 0.9090 - loss: 0.4709 - val_accuracy: 0.6950 - val_loss: 0.9547 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 825ms/step - accuracy: 0.9048 - loss: 0.4472 - val_accuracy: 0.7067 - val_loss: 0.9273 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 801ms/step - accuracy: 0.9147 - loss: 0.4221 - val_accuracy: 0.6900 - val_loss: 0.9413 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 828ms/step - accuracy: 0.9225 - loss: 0.4074 - val_accuracy: 0.7117 - val_loss: 0.9105 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - accuracy: 0.9517 - loss: 0.3521\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 829ms/step - accuracy: 0.9515 - loss: 0.3523 - val_accuracy: 0.6917 - val_loss: 1.0760 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 804ms/step - accuracy: 0.9472 - loss: 0.3455 - val_accuracy: 0.7150 - val_loss: 0.9236 - learning_rate: 5.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 833ms/step - accuracy: 0.9428 - loss: 0.3384 - val_accuracy: 0.7100 - val_loss: 0.9807 - learning_rate: 5.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 804ms/step - accuracy: 0.9530 - loss: 0.3185 - val_accuracy: 0.7150 - val_loss: 0.9925 - learning_rate: 5.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 801ms/step - accuracy: 0.9590 - loss: 0.3073 - val_accuracy: 0.7050 - val_loss: 1.0946 - learning_rate: 5.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step - accuracy: 0.9624 - loss: 0.2917\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 835ms/step - accuracy: 0.9624 - loss: 0.2917 - val_accuracy: 0.7067 - val_loss: 1.0234 - learning_rate: 5.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 803ms/step - accuracy: 0.9675 - loss: 0.2938 - val_accuracy: 0.7167 - val_loss: 1.0130 - learning_rate: 2.5000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 811ms/step - accuracy: 0.9757 - loss: 0.2776 - val_accuracy: 0.7017 - val_loss: 1.0880 - learning_rate: 2.5000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 803ms/step - accuracy: 0.9702 - loss: 0.2822 - val_accuracy: 0.7200 - val_loss: 1.0534 - learning_rate: 2.5000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 811ms/step - accuracy: 0.9715 - loss: 0.2839 - val_accuracy: 0.7183 - val_loss: 1.0134 - learning_rate: 2.5000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742ms/step - accuracy: 0.9781 - loss: 0.2715\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 813ms/step - accuracy: 0.9781 - loss: 0.2715 - val_accuracy: 0.7100 - val_loss: 1.0912 - learning_rate: 2.5000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 810ms/step - accuracy: 0.9769 - loss: 0.2649 - val_accuracy: 0.7133 - val_loss: 1.0824 - learning_rate: 1.2500e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 842ms/step - accuracy: 0.9845 - loss: 0.2648 - val_accuracy: 0.7150 - val_loss: 1.0596 - learning_rate: 1.2500e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 828ms/step - accuracy: 0.9795 - loss: 0.2684 - val_accuracy: 0.7167 - val_loss: 1.0614 - learning_rate: 1.2500e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 816ms/step - accuracy: 0.9740 - loss: 0.2626 - val_accuracy: 0.7233 - val_loss: 1.0757 - learning_rate: 1.2500e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step - accuracy: 0.9744 - loss: 0.2577\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 887ms/step - accuracy: 0.9744 - loss: 0.2578 - val_accuracy: 0.7200 - val_loss: 1.0560 - learning_rate: 1.2500e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the accuracy and loss\n",
        "final_accuracy = history.history['accuracy'][-1]\n",
        "final_loss = history.history['loss'][-1]\n",
        "\n",
        "# Printing the final training accuracy and loss\n",
        "print(f'Final Training Accuracy : {final_accuracy}')\n",
        "print(f'Final Training Loss : {final_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d_BTVT70si1",
        "outputId": "e0909a11-7ccd-417e-af33-653f04394c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training Accuracy : 0.9715277552604675\n",
            "Final Training Loss : 0.2633870244026184\n"
          ]
        }
      ]
    }
  ]
}